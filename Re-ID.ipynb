{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madelezhia/Re-ID/blob/main/Re-ID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXnArRAUMsd-"
      },
      "source": [
        "# 🧪 Re-ID *from scratch*\n",
        "**Objectif** : comprendre « embedding layer » en 15 min.<br>\n",
        "**Dataset** : 10 personnes de Market-1501 (17 Mo)<br>\n",
        "**Modèle** : ResNet50 → Global Average Pooling → Linear(2048→256) → Triplet-Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfgCzp-fMsd-",
        "outputId": "ee060f5f-c5af-4a03-f6e1-9dd9ad88713c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=25848b5582842828b4a3f7bf41c92c2621a9e7bd336027f244c88c1df25c9bd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "# 1. Installs (Colab uniquement)\n",
        "!pip install torch torchvision tqdm wget"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive # AJOUTE\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "os.chdir(f'/gdrive/MyDrive/Colab Notebooks/2025-09 Re-ID/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlkM363nPAQf",
        "outputId": "f984b2e4-2dce-463b-d6e4-8f83d8f6fe22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuiizgLgMsd-",
        "outputId": "5310bbbd-8457-4e95-e208-6be593355c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDs retenues : ['0002', '0007', '0010', '0011', '0012', '0020', '0022', '0023', '0027', '0028']\n"
          ]
        }
      ],
      "source": [
        "# 2. Copier-coller 10 identités depuis Market-1501 complet\n",
        "import shutil, os, random\n",
        "source_dir = 'Market-1501-v15.09.15/Market-1501-v15.09.15/bounding_box_train'  # chemin après décompression\n",
        "target_dir = 'mini_market'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# liste des 10 premières identités (tu peux changer)\n",
        "ids = sorted({name[:4] for name in os.listdir(source_dir) if name.endswith('.jpg')})[:10]\n",
        "print('IDs retenues :', ids)\n",
        "\n",
        "for id_ in ids:\n",
        "    for img in os.listdir(source_dir):\n",
        "        if img.startswith(id_):\n",
        "            shutil.copy(os.path.join(source_dir, img), os.path.join(target_dir, img))\n",
        "\n",
        "print('✅ Mini-dataset créé :', len(os.listdir(target_dir)), 'images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C40udXU4Msd-"
      },
      "outputs": [],
      "source": [
        "# 3. Imports\n",
        "import torch, torchvision, random, PIL\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device :', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWb4hEJsMsd-"
      },
      "outputs": [],
      "source": [
        "# 4. Dataset & Dataloader\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256,128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder('mini_market', transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "print('Nombre d’identités :', len(dataset.classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44e8PpDsMsd-"
      },
      "outputs": [],
      "source": [
        "# 5. Modèle : ResNet50 → embedding 256-D\n",
        "class ReIDNet(nn.Module):\n",
        "    def __init__(self, embed_dim=256):\n",
        "        super().__init__()\n",
        "        base = torchvision.models.resnet50(pretrained=True)\n",
        "        self.backbone = nn.Sequential(*list(base.children())[:-2])  # pas de classifier\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.embed = nn.Linear(2048, embed_dim)   # ⬅️ embedding layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone(x)      # [B,2048,8,4]\n",
        "        feat = self.pool(feat).flatten(1)  # [B,2048]\n",
        "        return self.embed(feat)      # [B,256]\n",
        "\n",
        "model = ReIDNet().to(device)\n",
        "print('Modèle créé – 256-D embedding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r1jRjeSMsd-"
      },
      "outputs": [],
      "source": [
        "# 6. Triplet-Loss simplifiée (Batch-All strategy)\n",
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=0.3):\n",
        "        super().__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, embeds, labels):\n",
        "        pairwise_dist = torch.cdist(embeds, embeds, p=2)\n",
        "        mask_pos = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
        "        mask_neg = ~mask_pos\n",
        "        triplet_loss = 0.0\n",
        "        count = 0\n",
        "        for i in range(len(labels)):\n",
        "            pos = pairwise_dist[i][mask_pos[i]]\n",
        "            neg = pairwise_dist[i][mask_neg[i]]\n",
        "            if pos.numel()==0 or neg.numel()==0: continue\n",
        "            hardest_pos = pos.max()\n",
        "            hardest_neg = neg.min()\n",
        "            loss = torch.relu(hardest_pos - hardest_neg + self.margin)\n",
        "            triplet_loss += loss\n",
        "            count += 1\n",
        "        return triplet_loss / (count + 1e-8)\n",
        "\n",
        "criterion = TripletLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JS6JoKvMsd-"
      },
      "outputs": [],
      "source": [
        "# 7. Optimiseur & boucle d’entraînement\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "model.train()\n",
        "for epoch in range(5):\n",
        "    running_loss = 0.0\n",
        "    for imgs, labels in tqdm(dataloader, desc=f'Epoch {epoch+1}'):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        embeds = model(imgs)\n",
        "        loss = criterion(embeds, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Loss : {running_loss/len(dataloader):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-XqV8pMMsd-"
      },
      "outputs": [],
      "source": [
        "# 8. Visualisation rapide : distance entre 2 images\n",
        "model.eval()\n",
        "img1, label1 = dataset[0]   # identité 0\n",
        "img2, label2 = dataset[80]  # identité 1 (différente)\n",
        "with torch.no_grad():\n",
        "    e1 = model(img1.unsqueeze(0).to(device))\n",
        "    e2 = model(img2.unsqueeze(0).to(device))\n",
        "    dist = torch.cdist(e1, e2).item()\n",
        "print(f'Distance embedding : {dist:.3f}  (petit = même personne)')\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1); plt.imshow(transforms.ToPILImage()(img1)); plt.title(f'ID {label1}')\n",
        "plt.subplot(1,2,2); plt.imshow(transforms.ToPILImage()(img2)); plt.title(f'ID {label2}')\n",
        "plt.suptitle(f'Distance = {dist:.3f}'); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH_A50YlMsd-"
      },
      "source": [
        "### ✅ Tu viens de :  \n",
        "- créer un **embedding layer**  \n",
        "- l’entraîner avec **Triplet-Loss**  \n",
        "- visualiser la **distance** entre deux images  \n",
        "\n",
        "**Prochaine étape** : on supprime les visages (GDPR) et on exporte le modèle (ONNX).  \n",
        "Dis-moi quand tu as exécuté ce notebook !"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}